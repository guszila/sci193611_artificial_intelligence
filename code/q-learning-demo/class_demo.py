#!/usr/bin/env python3
"""
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Q-Learning ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡∏ï‡πà‡∏≤‡∏á‡πÜ
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏ò‡∏¥‡∏ï‡πÉ‡∏ô‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
"""

from simple_q_learning import SimpleGridWorld, SimpleQLearning

def demo_for_class():
    """Demo ‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ô‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"""
    
    print("üéì Q-Learning Class Demo")
    print("=" * 30)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á environment
    difficulties = ['easy', 'normal', 'hard', 'maze']
    
    print("1. ‡πÅ‡∏™‡∏î‡∏á Environment ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö:")
    for i, diff in enumerate(difficulties, 1):
        print(f"\n{i}. ‡∏£‡∏∞‡∏î‡∏±‡∏ö {diff.upper()}:")
        env = SimpleGridWorld(size=4, difficulty=diff)
        print(f"   ‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ: {env.count_obstacles()} ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á")
        print(f"   ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏™‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î: {env.get_optimal_path_length()} steps")
        env.print_grid()
    
    # ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ù‡∏∂‡∏Å Hard level
    print("\n2. ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ù‡∏∂‡∏Å Hard Level:")
    print("-" * 30)
    
    env = SimpleGridWorld(size=4, difficulty='hard')
    agent = SimpleQLearning(
        n_states=16,
        n_actions=4,
        learning_rate=0.1,
        discount=0.9,
        epsilon=0.3
    )
    
    print("‡∏Å‡πà‡∏≠‡∏ô‡∏ù‡∏∂‡∏Å:")
    reward_before, steps_before, _ = agent.test(env, show_path=False)
    print(f"  Reward: {reward_before:.2f}, Steps: {steps_before}")
    
    print("\n‡∏ù‡∏∂‡∏Å 500 episodes...")
    agent.train(env, episodes=500)
    
    print("‡∏´‡∏•‡∏±‡∏á‡∏ù‡∏∂‡∏Å:")
    reward_after, steps_after, _ = agent.test(env, show_path=False)
    print(f"  Reward: {reward_after:.2f}, Steps: {steps_after}")
    
    improvement = ((reward_after - reward_before) / abs(reward_before) * 100) if reward_before != 0 else 100
    print(f"  ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤: {improvement:.1f}%")
    
    print("\n3. Policy ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ:")
    policy = agent.get_policy()
    env.reset()
    env.print_grid(policy=policy)
    
 
    print("- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å Easy ‚Üí Normal ‚Üí Hard ‚Üí Maze")
    print("- ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤ complexity ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô ‚Üí ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏¢‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô")
    print("- ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö performance ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö")
    print("- ‡πÉ‡∏´‡πâ‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå")

if __name__ == "__main__":
    demo_for_class()
